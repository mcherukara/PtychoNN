{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from numpy.fft import fftn, fftshift\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: 1 Batch size: 64 Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "NGPUS = torch.cuda.device_count()\n",
    "BATCH_SIZE = NGPUS * 64\n",
    "LR = NGPUS * 1e-3\n",
    "print(\"GPUs:\", NGPUS, \"Batch size:\", BATCH_SIZE, \"Learning rate:\", LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 64,64\n",
    "NLINES = 100 #How many lines of data to use for training?\n",
    "NLTEST = 60 #How many lines for the test set?\n",
    "\n",
    "N_VALID = 805 #How much to reserve for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "MODEL_SAVE_PATH = path +'/trained_model/'\n",
    "if (not os.path.isdir(MODEL_SAVE_PATH)):\n",
    "    os.mkdir(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 161, 64, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diffr = np.load(path+'/../../data/20191008_39_diff.npz')['arr_0']\n",
    "real_space = np.load(path+'/../../data/20191008_39_amp_pha_10nm_full.npy')\n",
    "amp = np.abs(real_space)\n",
    "ph = np.angle(real_space)\n",
    "amp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/161 [00:00<00:24,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 161, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:23<00:00,  6.75it/s]\n"
     ]
    }
   ],
   "source": [
    "print(data_diffr.shape)\n",
    "#plt.matshow(np.log10(data_diffr[0,0]))\n",
    "\n",
    "data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)\n",
    "for i in tqdm(range(data_diffr.shape[0])):\n",
    "    for j in range(data_diffr.shape[1]):\n",
    "        data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)\n",
    "        data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "(16100, 1, 64, 64) (3600, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "tst_strt = amp.shape[0]-NLTEST #Where to index from\n",
    "print(tst_strt)\n",
    "\n",
    "X_train = data_diffr_red[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Y_I_train = amp[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Y_I_test = amp[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Y_phi_train = ph[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "Y_phi_test = ph[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "ntrain = X_train.shape[0]*X_train.shape[1]\n",
    "ntest = X_test.shape[0]*X_test.shape[1]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "X_train, Y_I_train, Y_phi_train = shuffle(X_train, Y_I_train, Y_phi_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1268637 -1.564053\n",
      "torch.Size([16100, 1, 64, 64]) torch.Size([16100, 1, 64, 64]) torch.Size([16100, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#Training data\n",
    "X_train_tensor = torch.Tensor(X_train) \n",
    "Y_I_train_tensor = torch.Tensor(Y_I_train) \n",
    "Y_phi_train_tensor = torch.Tensor(Y_phi_train)\n",
    "\n",
    "#Test data\n",
    "X_test_tensor = torch.Tensor(X_test) \n",
    "Y_I_test_tensor = torch.Tensor(Y_I_test) \n",
    "Y_phi_test_tensor = torch.Tensor(Y_phi_test)\n",
    "\n",
    "print(Y_phi_train.max(), Y_phi_train.min())\n",
    "\n",
    "print(X_train_tensor.shape, Y_I_train_tensor.shape, Y_phi_train_tensor.shape)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor,Y_I_train_tensor,Y_phi_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15295 805 3600\n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = X_train_tensor.shape[0]\n",
    "train_data2, valid_data = torch.utils.data.random_split(train_data,[N_TRAIN-N_VALID,N_VALID])\n",
    "print(len(train_data2),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and load training data\n",
    "trainloader = DataLoader(train_data2, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "validloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "#same for test\n",
    "#download and load training data\n",
    "testloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nconv = 32\n",
    "\n",
    "\n",
    "class recon_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(recon_model, self).__init__()\n",
    "\n",
    "\n",
    "        self.encoder = nn.Sequential( # Appears sequential has similar functionality as TF avoiding need for separate model definition and activ\n",
    "          nn.Conv2d(in_channels=1, out_channels=nconv, kernel_size=3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv, nconv, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d((2,2)),\n",
    "\n",
    "          nn.Conv2d(nconv, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),          \n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d((2,2)),\n",
    "\n",
    "          nn.Conv2d(nconv*2, nconv*4, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*4, nconv*4, 3, stride=1, padding=(1,1)),          \n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d((2,2)),\n",
    "          )\n",
    "\n",
    "        self.decoder1 = nn.Sequential(\n",
    "\n",
    "          nn.Conv2d(nconv*4, nconv*4, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*4, nconv*4, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "          nn.Conv2d(nconv*4, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            \n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "          nn.Conv2d(nconv*2, 1, 3, stride=1, padding=(1,1)),\n",
    "          nn.Sigmoid() #Amplitude model\n",
    "          )\n",
    "\n",
    "        self.decoder2 = nn.Sequential(\n",
    "\n",
    "          nn.Conv2d(nconv*4, nconv*4, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*4, nconv*4, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "          nn.Conv2d(nconv*4, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            \n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(nconv*2, nconv*2, 3, stride=1, padding=(1,1)),\n",
    "          nn.ReLU(),\n",
    "          nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "          nn.Conv2d(nconv*2, 1, 3, stride=1, padding=(1,1)),\n",
    "          nn.Tanh() #Phase model\n",
    "          )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = self.encoder(x)\n",
    "        amp = self.decoder1(x1)\n",
    "        ph = self.decoder2(x1)\n",
    "\n",
    "        #Restore -pi to pi range\n",
    "        ph = ph*np.pi #Using tanh activation (-1 to 1) for phase so multiply by pi\n",
    "\n",
    "        return amp,ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcheruka/PyTorch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/mcheruka/PyTorch/lib/python3.8/site-packages/torch/nn/functional.py:3590: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64]) torch.Size([64, 1, 64, 64])\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "model = recon_model()\n",
    "for ft_images,amps,phs in trainloader:\n",
    "    print(\"batch size:\", ft_images.shape)\n",
    "    amp, ph = model(ft_images)\n",
    "    print(amp.shape, ph.shape)\n",
    "    print(amp.dtype, ph.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 8, 8]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 64, 64]          320\n",
      "|    └─ReLU: 2-2                         [-1, 32, 64, 64]          --\n",
      "|    └─Conv2d: 2-3                       [-1, 32, 64, 64]          9,248\n",
      "|    └─ReLU: 2-4                         [-1, 32, 64, 64]          --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 32, 32, 32]          --\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 32, 32]          18,496\n",
      "|    └─ReLU: 2-7                         [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-8                       [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-9                         [-1, 64, 32, 32]          --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 64, 16, 16]          --\n",
      "|    └─Conv2d: 2-11                      [-1, 128, 16, 16]         73,856\n",
      "|    └─ReLU: 2-12                        [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 16, 16]         147,584\n",
      "|    └─ReLU: 2-14                        [-1, 128, 16, 16]         --\n",
      "|    └─MaxPool2d: 2-15                   [-1, 128, 8, 8]           --\n",
      "├─Sequential: 1-2                        [-1, 1, 64, 64]           --\n",
      "|    └─Conv2d: 2-16                      [-1, 128, 8, 8]           147,584\n",
      "|    └─ReLU: 2-17                        [-1, 128, 8, 8]           --\n",
      "|    └─Conv2d: 2-18                      [-1, 128, 8, 8]           147,584\n",
      "|    └─ReLU: 2-19                        [-1, 128, 8, 8]           --\n",
      "|    └─Upsample: 2-20                    [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-21                      [-1, 64, 16, 16]          73,792\n",
      "|    └─ReLU: 2-22                        [-1, 64, 16, 16]          --\n",
      "|    └─Conv2d: 2-23                      [-1, 64, 16, 16]          36,928\n",
      "|    └─ReLU: 2-24                        [-1, 64, 16, 16]          --\n",
      "|    └─Upsample: 2-25                    [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-26                      [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-27                        [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-28                      [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-29                        [-1, 64, 32, 32]          --\n",
      "|    └─Upsample: 2-30                    [-1, 64, 64, 64]          --\n",
      "|    └─Conv2d: 2-31                      [-1, 1, 64, 64]           577\n",
      "|    └─Sigmoid: 2-32                     [-1, 1, 64, 64]           --\n",
      "├─Sequential: 1-3                        [-1, 1, 64, 64]           --\n",
      "|    └─Conv2d: 2-33                      [-1, 128, 8, 8]           147,584\n",
      "|    └─ReLU: 2-34                        [-1, 128, 8, 8]           --\n",
      "|    └─Conv2d: 2-35                      [-1, 128, 8, 8]           147,584\n",
      "|    └─ReLU: 2-36                        [-1, 128, 8, 8]           --\n",
      "|    └─Upsample: 2-37                    [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-38                      [-1, 64, 16, 16]          73,792\n",
      "|    └─ReLU: 2-39                        [-1, 64, 16, 16]          --\n",
      "|    └─Conv2d: 2-40                      [-1, 64, 16, 16]          36,928\n",
      "|    └─ReLU: 2-41                        [-1, 64, 16, 16]          --\n",
      "|    └─Upsample: 2-42                    [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-43                      [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-44                        [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-45                      [-1, 64, 32, 32]          36,928\n",
      "|    └─ReLU: 2-46                        [-1, 64, 32, 32]          --\n",
      "|    └─Upsample: 2-47                    [-1, 64, 64, 64]          --\n",
      "|    └─Conv2d: 2-48                      [-1, 1, 64, 64]           577\n",
      "|    └─Tanh: 2-49                        [-1, 1, 64, 64]           --\n",
      "==========================================================================================\n",
      "Total params: 1,247,074\n",
      "Trainable params: 1,247,074\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 403.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 6.31\n",
      "Params size (MB): 4.76\n",
      "Estimated Total Size (MB): 11.09\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,H,W),device=\"cpu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model) #Default all devices\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR step size is: 1434.0 which is every 6 epochs\n"
     ]
    }
   ],
   "source": [
    "#Optimizer details\n",
    "iterations_per_epoch = np.floor((N_TRAIN-N_VALID)/BATCH_SIZE)+1 #Final batch will be less than batch size\n",
    "step_size = 6*iterations_per_epoch #Paper recommends 2-10 number of iterations, step_size is half cycle\n",
    "print(\"LR step size is:\", step_size, \"which is every %d epochs\" %(step_size/iterations_per_epoch))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, step_size_up=step_size,\n",
    "                                              cycle_momentum=False, mode='triangular2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to update saved model if validation loss is minimum\n",
    "def update_saved_model(model, path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    for f in os.listdir(path):\n",
    "        os.remove(os.path.join(path, f))\n",
    "    if (NGPUS>1):    \n",
    "        torch.save(model.module.state_dict(),path+'best_model.pth') #Have to save the underlying model else will always need 4 GPUs\n",
    "    else:\n",
    "        torch.save(model,path+'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader,metrics):\n",
    "    tot_loss = 0.0\n",
    "    loss_amp = 0.0\n",
    "    loss_ph = 0.0\n",
    "    \n",
    "    for i, (ft_images,amps,phs) in tqdm(enumerate(trainloader)):\n",
    "        ft_images = ft_images.to(device) #Move everything to device\n",
    "        amps = amps.to(device)\n",
    "        phs = phs.to(device)\n",
    "\n",
    "        pred_amps, pred_phs = model(ft_images) #Forward pass\n",
    "\n",
    "        #Compute losses\n",
    "        loss_a = criterion(pred_amps,amps) #Monitor amplitude loss\n",
    "        loss_p = criterion(pred_phs,phs) #Monitor phase loss but only within support (which may not be same as true amp)\n",
    "        loss = loss_a + loss_p #Use equiweighted amps and phase\n",
    "\n",
    "        #Zero current grads and do backprop\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot_loss += loss.detach().item()\n",
    "        loss_amp += loss_a.detach().item()\n",
    "        loss_ph += loss_p.detach().item()\n",
    "\n",
    "        #Update the LR according to the schedule -- CyclicLR updates each batch\n",
    "        scheduler.step() \n",
    "        metrics['lrs'].append(scheduler.get_last_lr())\n",
    "        \n",
    "        \n",
    "    #Divide cumulative loss by number of batches-- sli inaccurate because last batch is different size\n",
    "    metrics['losses'].append([tot_loss/i,loss_amp/i,loss_ph/i]) \n",
    "    \n",
    "\n",
    "def validate(validloader,metrics):\n",
    "    tot_val_loss = 0.0\n",
    "    val_loss_amp = 0.0\n",
    "    val_loss_ph = 0.0\n",
    "    for j, (ft_images,amps,phs) in enumerate(validloader):\n",
    "        ft_images = ft_images.to(device)\n",
    "        amps = amps.to(device)\n",
    "        phs = phs.to(device)\n",
    "        pred_amps, pred_phs = model(ft_images) #Forward pass\n",
    "    \n",
    "        val_loss_a = criterion(pred_amps,amps) \n",
    "        val_loss_p = criterion(pred_phs,phs)\n",
    "        val_loss = val_loss_a + val_loss_p\n",
    "    \n",
    "        tot_val_loss += val_loss.detach().item()\n",
    "        val_loss_amp += val_loss_a.detach().item()\n",
    "        val_loss_ph += val_loss_p.detach().item()  \n",
    "    metrics['val_losses'].append([tot_val_loss/j,val_loss_amp/j,val_loss_ph/j])\n",
    "  \n",
    "  #Update saved model if val loss is lower\n",
    "    if(tot_val_loss/j<metrics['best_val_loss']):\n",
    "        print(\"Saving improved model after Val Loss improved from %.5f to %.5f\" %(metrics['best_val_loss'],tot_val_loss/j))\n",
    "        metrics['best_val_loss'] = tot_val_loss/j\n",
    "        update_saved_model(model, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:07, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from inf to 0.66021\n",
      "Epoch: 0 | FT  | Train Loss: 0.72994 | Val Loss: 0.66021\n",
      "Epoch: 0 | Amp | Train Loss: 0.0810 | Val Loss: 0.0223\n",
      "Epoch: 0 | Ph  | Train Loss: 0.649 | Val Loss: 0.638\n",
      "Epoch: 0 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.66021 to 0.56567\n",
      "Epoch: 1 | FT  | Train Loss: 0.53959 | Val Loss: 0.56567\n",
      "Epoch: 1 | Amp | Train Loss: 0.0186 | Val Loss: 0.0202\n",
      "Epoch: 1 | Ph  | Train Loss: 0.521 | Val Loss: 0.545\n",
      "Epoch: 1 | Ending LR: 0.000400 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.56567 to 0.43987\n",
      "Epoch: 2 | FT  | Train Loss: 0.44057 | Val Loss: 0.43987\n",
      "Epoch: 2 | Amp | Train Loss: 0.0152 | Val Loss: 0.0115\n",
      "Epoch: 2 | Ph  | Train Loss: 0.425 | Val Loss: 0.428\n",
      "Epoch: 2 | Ending LR: 0.000550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.43987 to 0.38822\n",
      "Epoch: 3 | FT  | Train Loss: 0.37922 | Val Loss: 0.38822\n",
      "Epoch: 3 | Amp | Train Loss: 0.0130 | Val Loss: 0.0110\n",
      "Epoch: 3 | Ph  | Train Loss: 0.366 | Val Loss: 0.377\n",
      "Epoch: 3 | Ending LR: 0.000700 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.38822 to 0.35840\n",
      "Epoch: 4 | FT  | Train Loss: 0.34471 | Val Loss: 0.35840\n",
      "Epoch: 4 | Amp | Train Loss: 0.0132 | Val Loss: 0.0094\n",
      "Epoch: 4 | Ph  | Train Loss: 0.332 | Val Loss: 0.349\n",
      "Epoch: 4 | Ending LR: 0.000850 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | FT  | Train Loss: 0.31348 | Val Loss: 0.36241\n",
      "Epoch: 5 | Amp | Train Loss: 0.0085 | Val Loss: 0.0085\n",
      "Epoch: 5 | Ph  | Train Loss: 0.305 | Val Loss: 0.354\n",
      "Epoch: 5 | Ending LR: 0.001000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.35840 to 0.28927\n",
      "Epoch: 6 | FT  | Train Loss: 0.28322 | Val Loss: 0.28927\n",
      "Epoch: 6 | Amp | Train Loss: 0.0070 | Val Loss: 0.0071\n",
      "Epoch: 6 | Ph  | Train Loss: 0.276 | Val Loss: 0.282\n",
      "Epoch: 6 | Ending LR: 0.000850 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.28927 to 0.26462\n",
      "Epoch: 7 | FT  | Train Loss: 0.24729 | Val Loss: 0.26462\n",
      "Epoch: 7 | Amp | Train Loss: 0.0064 | Val Loss: 0.0073\n",
      "Epoch: 7 | Ph  | Train Loss: 0.241 | Val Loss: 0.257\n",
      "Epoch: 7 | Ending LR: 0.000700 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.26462 to 0.23901\n",
      "Epoch: 8 | FT  | Train Loss: 0.21993 | Val Loss: 0.23901\n",
      "Epoch: 8 | Amp | Train Loss: 0.0062 | Val Loss: 0.0067\n",
      "Epoch: 8 | Ph  | Train Loss: 0.214 | Val Loss: 0.232\n",
      "Epoch: 8 | Ending LR: 0.000550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.23901 to 0.21759\n",
      "Epoch: 9 | FT  | Train Loss: 0.19456 | Val Loss: 0.21759\n",
      "Epoch: 9 | Amp | Train Loss: 0.0061 | Val Loss: 0.0066\n",
      "Epoch: 9 | Ph  | Train Loss: 0.188 | Val Loss: 0.211\n",
      "Epoch: 9 | Ending LR: 0.000400 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.21759 to 0.20230\n",
      "Epoch: 10 | FT  | Train Loss: 0.17236 | Val Loss: 0.20230\n",
      "Epoch: 10 | Amp | Train Loss: 0.0060 | Val Loss: 0.0065\n",
      "Epoch: 10 | Ph  | Train Loss: 0.166 | Val Loss: 0.196\n",
      "Epoch: 10 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.20230 to 0.18761\n",
      "Epoch: 11 | FT  | Train Loss: 0.15395 | Val Loss: 0.18761\n",
      "Epoch: 11 | Amp | Train Loss: 0.0059 | Val Loss: 0.0065\n",
      "Epoch: 11 | Ph  | Train Loss: 0.148 | Val Loss: 0.181\n",
      "Epoch: 11 | Ending LR: 0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.18761 to 0.18689\n",
      "Epoch: 12 | FT  | Train Loss: 0.14436 | Val Loss: 0.18689\n",
      "Epoch: 12 | Amp | Train Loss: 0.0059 | Val Loss: 0.0064\n",
      "Epoch: 12 | Ph  | Train Loss: 0.138 | Val Loss: 0.180\n",
      "Epoch: 12 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | FT  | Train Loss: 0.14536 | Val Loss: 0.18835\n",
      "Epoch: 13 | Amp | Train Loss: 0.0058 | Val Loss: 0.0064\n",
      "Epoch: 13 | Ph  | Train Loss: 0.140 | Val Loss: 0.182\n",
      "Epoch: 13 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | FT  | Train Loss: 0.14969 | Val Loss: 0.19701\n",
      "Epoch: 14 | Amp | Train Loss: 0.0058 | Val Loss: 0.0063\n",
      "Epoch: 14 | Ph  | Train Loss: 0.144 | Val Loss: 0.191\n",
      "Epoch: 14 | Ending LR: 0.000325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | FT  | Train Loss: 0.15598 | Val Loss: 0.20200\n",
      "Epoch: 15 | Amp | Train Loss: 0.0058 | Val Loss: 0.0066\n",
      "Epoch: 15 | Ph  | Train Loss: 0.150 | Val Loss: 0.195\n",
      "Epoch: 15 | Ending LR: 0.000400 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | FT  | Train Loss: 0.16114 | Val Loss: 0.20084\n",
      "Epoch: 16 | Amp | Train Loss: 0.0058 | Val Loss: 0.0066\n",
      "Epoch: 16 | Ph  | Train Loss: 0.155 | Val Loss: 0.194\n",
      "Epoch: 16 | Ending LR: 0.000475 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | FT  | Train Loss: 0.16821 | Val Loss: 0.21114\n",
      "Epoch: 17 | Amp | Train Loss: 0.0058 | Val Loss: 0.0062\n",
      "Epoch: 17 | Ph  | Train Loss: 0.162 | Val Loss: 0.205\n",
      "Epoch: 17 | Ending LR: 0.000550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | FT  | Train Loss: 0.16140 | Val Loss: 0.18832\n",
      "Epoch: 18 | Amp | Train Loss: 0.0056 | Val Loss: 0.0061\n",
      "Epoch: 18 | Ph  | Train Loss: 0.156 | Val Loss: 0.182\n",
      "Epoch: 18 | Ending LR: 0.000475 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.18689 to 0.18006\n",
      "Epoch: 19 | FT  | Train Loss: 0.14681 | Val Loss: 0.18006\n",
      "Epoch: 19 | Amp | Train Loss: 0.0054 | Val Loss: 0.0060\n",
      "Epoch: 19 | Ph  | Train Loss: 0.141 | Val Loss: 0.174\n",
      "Epoch: 19 | Ending LR: 0.000400 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.18006 to 0.16719\n",
      "Epoch: 20 | FT  | Train Loss: 0.13395 | Val Loss: 0.16719\n",
      "Epoch: 20 | Amp | Train Loss: 0.0053 | Val Loss: 0.0059\n",
      "Epoch: 20 | Ph  | Train Loss: 0.129 | Val Loss: 0.161\n",
      "Epoch: 20 | Ending LR: 0.000325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.16719 to 0.16060\n",
      "Epoch: 21 | FT  | Train Loss: 0.12383 | Val Loss: 0.16060\n",
      "Epoch: 21 | Amp | Train Loss: 0.0052 | Val Loss: 0.0058\n",
      "Epoch: 21 | Ph  | Train Loss: 0.119 | Val Loss: 0.155\n",
      "Epoch: 21 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.16060 to 0.15415\n",
      "Epoch: 22 | FT  | Train Loss: 0.11446 | Val Loss: 0.15415\n",
      "Epoch: 22 | Amp | Train Loss: 0.0050 | Val Loss: 0.0057\n",
      "Epoch: 22 | Ph  | Train Loss: 0.109 | Val Loss: 0.148\n",
      "Epoch: 22 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.15415 to 0.14957\n",
      "Epoch: 23 | FT  | Train Loss: 0.10651 | Val Loss: 0.14957\n",
      "Epoch: 23 | Amp | Train Loss: 0.0049 | Val Loss: 0.0056\n",
      "Epoch: 23 | Ph  | Train Loss: 0.102 | Val Loss: 0.144\n",
      "Epoch: 23 | Ending LR: 0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.14957 to 0.14872\n",
      "Epoch: 24 | FT  | Train Loss: 0.10211 | Val Loss: 0.14872\n",
      "Epoch: 24 | Amp | Train Loss: 0.0048 | Val Loss: 0.0056\n",
      "Epoch: 24 | Ph  | Train Loss: 0.097 | Val Loss: 0.143\n",
      "Epoch: 24 | Ending LR: 0.000138 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | FT  | Train Loss: 0.10279 | Val Loss: 0.14905\n",
      "Epoch: 25 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055\n",
      "Epoch: 25 | Ph  | Train Loss: 0.098 | Val Loss: 0.144\n",
      "Epoch: 25 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | FT  | Train Loss: 0.10524 | Val Loss: 0.15151\n",
      "Epoch: 26 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055\n",
      "Epoch: 26 | Ph  | Train Loss: 0.100 | Val Loss: 0.146\n",
      "Epoch: 26 | Ending LR: 0.000213 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | FT  | Train Loss: 0.10903 | Val Loss: 0.15423\n",
      "Epoch: 27 | Amp | Train Loss: 0.0048 | Val Loss: 0.0056\n",
      "Epoch: 27 | Ph  | Train Loss: 0.104 | Val Loss: 0.149\n",
      "Epoch: 27 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | FT  | Train Loss: 0.11262 | Val Loss: 0.15704\n",
      "Epoch: 28 | Amp | Train Loss: 0.0049 | Val Loss: 0.0056\n",
      "Epoch: 28 | Ph  | Train Loss: 0.108 | Val Loss: 0.151\n",
      "Epoch: 28 | Ending LR: 0.000287 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | FT  | Train Loss: 0.11758 | Val Loss: 0.16143\n",
      "Epoch: 29 | Amp | Train Loss: 0.0049 | Val Loss: 0.0055\n",
      "Epoch: 29 | Ph  | Train Loss: 0.113 | Val Loss: 0.156\n",
      "Epoch: 29 | Ending LR: 0.000325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | FT  | Train Loss: 0.11850 | Val Loss: 0.15511\n",
      "Epoch: 30 | Amp | Train Loss: 0.0048 | Val Loss: 0.0055\n",
      "Epoch: 30 | Ph  | Train Loss: 0.114 | Val Loss: 0.150\n",
      "Epoch: 30 | Ending LR: 0.000287 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | FT  | Train Loss: 0.10893 | Val Loss: 0.14985\n",
      "Epoch: 31 | Amp | Train Loss: 0.0047 | Val Loss: 0.0054\n",
      "Epoch: 31 | Ph  | Train Loss: 0.104 | Val Loss: 0.144\n",
      "Epoch: 31 | Ending LR: 0.000250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.14872 to 0.14669\n",
      "Epoch: 32 | FT  | Train Loss: 0.10306 | Val Loss: 0.14669\n",
      "Epoch: 32 | Amp | Train Loss: 0.0045 | Val Loss: 0.0053\n",
      "Epoch: 32 | Ph  | Train Loss: 0.099 | Val Loss: 0.141\n",
      "Epoch: 32 | Ending LR: 0.000213 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.14669 to 0.14140\n",
      "Epoch: 33 | FT  | Train Loss: 0.09724 | Val Loss: 0.14140\n",
      "Epoch: 33 | Amp | Train Loss: 0.0044 | Val Loss: 0.0052\n",
      "Epoch: 33 | Ph  | Train Loss: 0.093 | Val Loss: 0.136\n",
      "Epoch: 33 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.14140 to 0.13875\n",
      "Epoch: 34 | FT  | Train Loss: 0.09239 | Val Loss: 0.13875\n",
      "Epoch: 34 | Amp | Train Loss: 0.0043 | Val Loss: 0.0052\n",
      "Epoch: 34 | Ph  | Train Loss: 0.088 | Val Loss: 0.134\n",
      "Epoch: 34 | Ending LR: 0.000138 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13875 to 0.13632\n",
      "Epoch: 35 | FT  | Train Loss: 0.08818 | Val Loss: 0.13632\n",
      "Epoch: 35 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051\n",
      "Epoch: 35 | Ph  | Train Loss: 0.084 | Val Loss: 0.131\n",
      "Epoch: 35 | Ending LR: 0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | FT  | Train Loss: 0.08569 | Val Loss: 0.13651\n",
      "Epoch: 36 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051\n",
      "Epoch: 36 | Ph  | Train Loss: 0.082 | Val Loss: 0.131\n",
      "Epoch: 36 | Ending LR: 0.000119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | FT  | Train Loss: 0.08600 | Val Loss: 0.13785\n",
      "Epoch: 37 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051\n",
      "Epoch: 37 | Ph  | Train Loss: 0.082 | Val Loss: 0.133\n",
      "Epoch: 37 | Ending LR: 0.000137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | FT  | Train Loss: 0.08766 | Val Loss: 0.13927\n",
      "Epoch: 38 | Amp | Train Loss: 0.0042 | Val Loss: 0.0052\n",
      "Epoch: 38 | Ph  | Train Loss: 0.083 | Val Loss: 0.134\n",
      "Epoch: 38 | Ending LR: 0.000156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | FT  | Train Loss: 0.08946 | Val Loss: 0.13981\n",
      "Epoch: 39 | Amp | Train Loss: 0.0042 | Val Loss: 0.0052\n",
      "Epoch: 39 | Ph  | Train Loss: 0.085 | Val Loss: 0.135\n",
      "Epoch: 39 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | FT  | Train Loss: 0.09143 | Val Loss: 0.14079\n",
      "Epoch: 40 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051\n",
      "Epoch: 40 | Ph  | Train Loss: 0.087 | Val Loss: 0.136\n",
      "Epoch: 40 | Ending LR: 0.000194 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | FT  | Train Loss: 0.09346 | Val Loss: 0.14118\n",
      "Epoch: 41 | Amp | Train Loss: 0.0042 | Val Loss: 0.0052\n",
      "Epoch: 41 | Ph  | Train Loss: 0.089 | Val Loss: 0.136\n",
      "Epoch: 41 | Ending LR: 0.000213 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | FT  | Train Loss: 0.09388 | Val Loss: 0.13938\n",
      "Epoch: 42 | Amp | Train Loss: 0.0042 | Val Loss: 0.0051\n",
      "Epoch: 42 | Ph  | Train Loss: 0.090 | Val Loss: 0.134\n",
      "Epoch: 42 | Ending LR: 0.000194 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | FT  | Train Loss: 0.08991 | Val Loss: 0.13820\n",
      "Epoch: 43 | Amp | Train Loss: 0.0041 | Val Loss: 0.0050\n",
      "Epoch: 43 | Ph  | Train Loss: 0.086 | Val Loss: 0.133\n",
      "Epoch: 43 | Ending LR: 0.000175 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13632 to 0.13539\n",
      "Epoch: 44 | FT  | Train Loss: 0.08641 | Val Loss: 0.13539\n",
      "Epoch: 44 | Amp | Train Loss: 0.0040 | Val Loss: 0.0050\n",
      "Epoch: 44 | Ph  | Train Loss: 0.082 | Val Loss: 0.130\n",
      "Epoch: 44 | Ending LR: 0.000156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13539 to 0.13419\n",
      "Epoch: 45 | FT  | Train Loss: 0.08362 | Val Loss: 0.13419\n",
      "Epoch: 45 | Amp | Train Loss: 0.0040 | Val Loss: 0.0050\n",
      "Epoch: 45 | Ph  | Train Loss: 0.080 | Val Loss: 0.129\n",
      "Epoch: 45 | Ending LR: 0.000137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13419 to 0.13264\n",
      "Epoch: 46 | FT  | Train Loss: 0.08101 | Val Loss: 0.13264\n",
      "Epoch: 46 | Amp | Train Loss: 0.0039 | Val Loss: 0.0049\n",
      "Epoch: 46 | Ph  | Train Loss: 0.077 | Val Loss: 0.128\n",
      "Epoch: 46 | Ending LR: 0.000119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13264 to 0.13140\n",
      "Epoch: 47 | FT  | Train Loss: 0.07873 | Val Loss: 0.13140\n",
      "Epoch: 47 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 47 | Ph  | Train Loss: 0.075 | Val Loss: 0.127\n",
      "Epoch: 47 | Ending LR: 0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | FT  | Train Loss: 0.07732 | Val Loss: 0.13239\n",
      "Epoch: 48 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 48 | Ph  | Train Loss: 0.074 | Val Loss: 0.127\n",
      "Epoch: 48 | Ending LR: 0.000109 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | FT  | Train Loss: 0.07784 | Val Loss: 0.13322\n",
      "Epoch: 49 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 49 | Ph  | Train Loss: 0.074 | Val Loss: 0.128\n",
      "Epoch: 49 | Ending LR: 0.000119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | FT  | Train Loss: 0.07843 | Val Loss: 0.13348\n",
      "Epoch: 50 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 50 | Ph  | Train Loss: 0.075 | Val Loss: 0.129\n",
      "Epoch: 50 | Ending LR: 0.000128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 38.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | FT  | Train Loss: 0.07954 | Val Loss: 0.13303\n",
      "Epoch: 51 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 51 | Ph  | Train Loss: 0.076 | Val Loss: 0.128\n",
      "Epoch: 51 | Ending LR: 0.000137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | FT  | Train Loss: 0.08027 | Val Loss: 0.13415\n",
      "Epoch: 52 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 52 | Ph  | Train Loss: 0.076 | Val Loss: 0.129\n",
      "Epoch: 52 | Ending LR: 0.000147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | FT  | Train Loss: 0.08150 | Val Loss: 0.13432\n",
      "Epoch: 53 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 53 | Ph  | Train Loss: 0.078 | Val Loss: 0.129\n",
      "Epoch: 53 | Ending LR: 0.000156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 | FT  | Train Loss: 0.08110 | Val Loss: 0.13270\n",
      "Epoch: 54 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 54 | Ph  | Train Loss: 0.077 | Val Loss: 0.128\n",
      "Epoch: 54 | Ending LR: 0.000147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 | FT  | Train Loss: 0.07970 | Val Loss: 0.13286\n",
      "Epoch: 55 | Amp | Train Loss: 0.0038 | Val Loss: 0.0049\n",
      "Epoch: 55 | Ph  | Train Loss: 0.076 | Val Loss: 0.128\n",
      "Epoch: 55 | Ending LR: 0.000137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13140 to 0.13135\n",
      "Epoch: 56 | FT  | Train Loss: 0.07785 | Val Loss: 0.13135\n",
      "Epoch: 56 | Amp | Train Loss: 0.0037 | Val Loss: 0.0048\n",
      "Epoch: 56 | Ph  | Train Loss: 0.074 | Val Loss: 0.127\n",
      "Epoch: 56 | Ending LR: 0.000128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13135 to 0.13120\n",
      "Epoch: 57 | FT  | Train Loss: 0.07606 | Val Loss: 0.13120\n",
      "Epoch: 57 | Amp | Train Loss: 0.0037 | Val Loss: 0.0049\n",
      "Epoch: 57 | Ph  | Train Loss: 0.072 | Val Loss: 0.126\n",
      "Epoch: 57 | Ending LR: 0.000119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving improved model after Val Loss improved from 0.13120 to 0.12957\n",
      "Epoch: 58 | FT  | Train Loss: 0.07465 | Val Loss: 0.12957\n",
      "Epoch: 58 | Amp | Train Loss: 0.0036 | Val Loss: 0.0048\n",
      "Epoch: 58 | Ph  | Train Loss: 0.071 | Val Loss: 0.125\n",
      "Epoch: 58 | Ending LR: 0.000109 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [00:06, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | FT  | Train Loss: 0.07348 | Val Loss: 0.12991\n",
      "Epoch: 59 | Amp | Train Loss: 0.0036 | Val Loss: 0.0048\n",
      "Epoch: 59 | Ph  | Train Loss: 0.070 | Val Loss: 0.125\n",
      "Epoch: 59 | Ending LR: 0.000100 \n"
     ]
    }
   ],
   "source": [
    "metrics = {'losses':[],'val_losses':[], 'lrs':[], 'best_val_loss' : np.inf}\n",
    "for epoch in range (EPOCHS):\n",
    "    \n",
    "  #Set model to train mode\n",
    "  model.train() \n",
    "    \n",
    "  #Training loop\n",
    "  train(trainloader,metrics)\n",
    "\n",
    "    \n",
    "  #Switch model to eval mode\n",
    "  model.eval()\n",
    "    \n",
    "  #Validation loop\n",
    "  validate(validloader,metrics)\n",
    "  \n",
    "  print('Epoch: %d | FT  | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][0], metrics['val_losses'][-1][0]))\n",
    "  print('Epoch: %d | Amp | Train Loss: %.4f | Val Loss: %.4f' %(epoch, metrics['losses'][-1][1], metrics['val_losses'][-1][1]))\n",
    "  print('Epoch: %d | Ph  | Train Loss: %.3f | Val Loss: %.3f' %(epoch, metrics['losses'][-1][2], metrics['val_losses'][-1][2]))\n",
    "  print('Epoch: %d | Ending LR: %.6f ' %(epoch, metrics['lrs'][-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcheruka/PyTorch/lib/python3.8/site-packages/torch/nn/functional.py:3590: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval() #imp when have dropout etc\n",
    "amps = []\n",
    "phs = []\n",
    "for i, ft_images in enumerate(testloader):\n",
    "    ft_images = ft_images[0].to(device)\n",
    "    amp, ph = model(ft_images)\n",
    "    for j in range(ft_images.shape[0]):\n",
    "        amps.append(amp[j].detach().to(\"cpu\").numpy())\n",
    "        phs.append(ph[j].detach().to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
